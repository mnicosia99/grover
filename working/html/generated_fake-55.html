<html><head><style> hr.solid { border-top: 3px solid #bbb;} figure { display: inline-block; border: 0px dotted gray; margin: 20px;text-align: center; } figure img { vertical-align: top; }</style></head><body><h1>SXE: Open Access at the Data Level</h1>
<p>Authors: James Wood Thomas Conrad Devin Garrett Vanessa Walton Jennifer Anderson </p>
Published Date: 11-05-2018<br/>
<hr class="solid">
<p>University of Central Arkansas</p>
School of Chemistry<br/>
<hr class="solid">
<br/><br/>Sci-Hub Exchange (SXE) is one of the most popular virtual environments for the free exchange of scientific data and information. SXE launched over a year ago with the mission to provide a platform for sharing all content where basic scientific discoveries can be turned into open-access and fully peer-reviewed publications, cutting-edge research, and datasets.<p>Over the past year, SXE has logged over 300,000 pre-print papers and 12 million research requests, and constantly monitors trends and growth, setting new records every day. More than 60,000 researchers are subscribed to our subscription service, allowing them to view higher-quality content than ever before. One of the major objectives of SXE is to provide a research community that is organized around the publication process, giving members the option to review and contribute original research directly from within the repository.<p>We have recently published a popular post by Sakthikumar Ambady, listing some of the more commonly-used tools and concepts to make scientific analysis easier. This post is an update of his previous one to update us on recent changes in SXE that could make the analytical process even easier, especially with new technologies.<p>The first step in good analytical research is adding in a new series of wells, where all data could be seen from each separate point. This provides a picture of the whole. By adding in one or two additional wells, it becomes extremely simple to manipulate the meta data and retrieve crucial information from the source.<p>Another useful feature of ESP IS is that it has multiple ways to link the source to the origin. One of these could be the specifics of the quality of data and the format. For example, the speed at which data was processed in the original is very important. The same information can be used for the analysis of the results or for identifying differences within data sets. Finally, we can extract and present this structure directly into a graphical diagram, a form of visual reporting that can be seen on our SXE platform.<p>In the video above, researcher Alexra Grella demonstrates that it is still possible to apply some of the developed techniques. Using ES cells (roughly four rows, around three inches deep), the visualization is clear for users. As we have seen in previous versions of EPS and PS research, new ASPs or a direct import of data has been possible in the past year, and it makes the analysis process even easier.<p>The Dallas Morning News called ESP IS a “vast haystack” of data. From this analogy, it is important to note that coding common XML flows (an excerpt of a found to be found process) into a specific data set does not require as much coding as doing the same thing with atomic or integer data, where it may be possible to work with just one chain of a particular set of sets, avoiding much of the extra code. That in itself allows us to perform much simpler analyses, bringing from our collective personal experience an open source, relevant and useful tool to our work.<p><figure><img src="http://mnicosia.tech/images/samples_5_55.png"/><figcaption>Test Caption</figcaption></figure></body></html>